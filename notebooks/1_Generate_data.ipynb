{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# install presidio via pip if not yet installed\n",
    "\n",
    "#!pip install presidio-analyzer\n",
    "#!pip install presidio-evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pprint\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from presidio_evaluator import InputSample\n",
    "from presidio_evaluator.data_generator import PresidioSentenceFaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate fake PII data using the Presidio Sentence Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Presidio Sentence Faker enables you to generate a synthetic dataset from sentence templates.\n",
    "Example templates:\n",
    "\n",
    "> I live at {{address}}\n",
    "\n",
    "> You can email me at {{email}}. Thanks, {{first_name}}\n",
    "\n",
    "> What's your last name? It's {{last_name}}\n",
    "\n",
    "> Every time I see you falling I get down on my knees and pray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple example\n",
    "This uses the default generator to create 10 samples based on three templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 9149.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Joshua Jackson\n",
      "[{\"value\": \"Joshua Jackson\", \"start\": 11, \"end\": 25, \"type\": \"name\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentence_templates = [\n",
    "    \"My name is {{name}}\",\n",
    "    \"Please send it to {{address}}\",\n",
    "    \"I just moved to {{city}} from {{country}}\",\n",
    "]\n",
    "\n",
    "\n",
    "sentence_faker = PresidioSentenceFaker('en_US', lower_case_ratio=0.05, sentence_templates=sentence_templates)\n",
    "fake_sentence_results = sentence_faker.generate_new_fake_sentences(10)\n",
    "\n",
    "# Print the spans of the first sample\n",
    "print(fake_sentence_results[0].fake)\n",
    "print(fake_sentence_results[0].spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a full dataset\n",
    "\n",
    "In this example we generate a large dataset with multiple entity types and save it in in JSON and CONLL03 formats.\n",
    "This uses the default sentence templates included in this package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_samples = 1500\n",
    "lower_case_ratio = 0.05\n",
    "locale = 'en'\n",
    "cur_time = datetime.date.today().strftime(\"%B_%d_%Y\")\n",
    "\n",
    "output_file = f\"../data/generated_size_{number_of_samples}_date_{cur_time}.json\"\n",
    "output_conll = f\"../data/generated_size_{number_of_samples}_date_{cur_time}.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The `PresidioSentenceFaker` loads [FakeNameGenerator](https://www.fakenamegenerator.com/) data by default\n",
    "to extend the set of fake values and creates a `RecordsFaker` \n",
    "which returns a fake person record (with multiple values) instead of one value,\n",
    "allowing dependencies between values belonging to the same fake person\n",
    "(e.g. name = Michael Smith with the email michael.smith@gmail.com).\n",
    "\n",
    "`FakeNameGenerator.com_3000.csv` is included in this package and can be sourced from https://www.fakenamegenerator.com/order.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_faker = PresidioSentenceFaker('en_US', lower_case_ratio=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sentence_faker._sentence_faker.faker.records).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PresidioSentenceFaker` adds additional providers by default, which are not included in the Faker package.\n",
    "These can be found in `presidio_evaluator.data_generator.faker_extensions.providers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from presidio_evaluator.data_generator.faker_extensions.providers import *\n",
    "\n",
    "IpAddressProvider  # Both Ipv4 and IPv6 IP addresses\n",
    "NationalityProvider  # Read countries + nationalities from file\n",
    "OrganizationProvider  # Read organization names from file\n",
    "UsDriverLicenseProvider  # Read US driver license numbers from file\n",
    "AgeProvider  # Age values (unavailable on Faker\n",
    "AddressProviderNew  # Extend the default address formats\n",
    "PhoneNumberProviderNew  # Extend the default phone number formats\n",
    "ReligionProvider  # Read religions from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`PresidioSentenceFaker.PROVIDER_ALIASES` can be extended to add additional provider aliases for when templates have\n",
    "a different entity name than what the providers emit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create entity aliases (e.g. if your provider supports \"name\" but templates contain \"person\").\n",
    "PresidioSentenceFaker.PROVIDER_ALIASES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_records = sentence_faker.generate_new_fake_sentences(num_samples=number_of_samples)\n",
    "pprint.pprint(fake_records[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify randomness of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1500\n",
      "Avg # of records per template: 7.142857142857143\n",
      "Median # of records per template: 7.0\n",
      "Std: 2.5872528966106905\n"
     ]
    }
   ],
   "source": [
    "count_per_template_id = Counter([sample.template_id for sample in fake_records])\n",
    "\n",
    "print(f\"Total: {sum(count_per_template_id.values())}\")\n",
    "print(f\"Avg # of records per template: {np.mean(list(count_per_template_id.values()))}\")\n",
    "print(f\"Median # of records per template: {np.median(list(count_per_template_id.values()))}\")\n",
    "print(f\"Std: {np.std(list(count_per_template_id.values()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Which entities did we generate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'organization': 257,\n",
       "         'first_name': 244,\n",
       "         'person': 238,\n",
       "         'city': 235,\n",
       "         'address': 209,\n",
       "         'street_name': 164,\n",
       "         'name': 162,\n",
       "         'country': 154,\n",
       "         'credit_card_number': 152,\n",
       "         'phone_number': 121,\n",
       "         'last_name': 119,\n",
       "         'building_number': 110,\n",
       "         'age': 72,\n",
       "         'secondary_address': 64,\n",
       "         'year': 58,\n",
       "         'nationality': 55,\n",
       "         'postcode': 49,\n",
       "         'zipcode': 45,\n",
       "         'url': 39,\n",
       "         'email': 39,\n",
       "         'name_female': 37,\n",
       "         'job': 33,\n",
       "         'first_name_male': 31,\n",
       "         'name_male': 29,\n",
       "         'prefix_male': 28,\n",
       "         'date_of_birth': 24,\n",
       "         'iban': 22,\n",
       "         'date_time': 21,\n",
       "         'prefix_female': 21,\n",
       "         'day_of_week': 16,\n",
       "         'state_abbr': 15,\n",
       "         'last_name_male': 15,\n",
       "         'prefix': 12,\n",
       "         'ip_address': 11,\n",
       "         'ssn': 11,\n",
       "         'nation_plural': 9,\n",
       "         'nation_woman': 8,\n",
       "         'first_name_nonbinary': 6,\n",
       "         'us_driver_license': 6,\n",
       "         'first_name_female': 3,\n",
       "         'last_name_female': 3})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_per_entity = Counter()\n",
    "for record in fake_records:\n",
    "    count_per_entity.update(Counter([span.type for span in record.spans]))\n",
    "\n",
    "count_per_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dataclasses\n",
    "def get_json(result) -> str:\n",
    "    spans_dict = json.dumps([dataclasses.asdict(span) for span in result.spans])\n",
    "    return dict(fake=result.fake, spans=spans_dict, template=result.template, template_id=result.template_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"fake\": \"Title VII of the Civil Rights Act of 2005 protects individuals against employment discrimination on the basis of race and color as well as national origin, sex, or religion.\\n\", \"spans\": [{\"value\": \"2005\", \"start\": 37, \"end\": 41, \"type\": \"DATE_TIME\"}], \"template\": \"Title VII of the Civil Rights Act of {{DATE_TIME}} protects individuals against employment discrimination on the basis of race and color as well as national origin, sex, or religion.\\n\", \"template_id\": 190}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fake_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in fake_records[:10]:\n",
    "    print(get_json(record))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize and transform the fake samples to a list of `InputSample` objects (Common data structure for this package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the spaCy tokenizer model if missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                   | 0/1500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model en_core_web_sm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:06<00:00, 215.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.76 s, sys: 33.8 ms, total: 6.8 s\n",
      "Wall time: 6.96 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_samples = [\n",
    "    InputSample.from_faker_spans_result(faker_spans_result=fake_record)\n",
    "    for fake_record in tqdm.tqdm(fake_records)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Save as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "InputSample.to_json(dataset=input_samples, output_file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create a CONLL like data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1500/1500 [00:00<00:00, 76888.23it/s]\n"
     ]
    }
   ],
   "source": [
    "conll = InputSample.create_conll_dataset(input_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conll.to_csv(output_conll, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "- Evaluate Presidio using this fake data: [Sample](4_Evaluate_Presidio_Analyzer.ipynb)\n",
    "- Split to train/test/validation while ensuring sentences originiating from the same template are all on the same subset: [Sample](3_Split_by_pattern_#.ipynb)\n",
    "- Conduct a small exploratory data analysis on the generated data: [Sample](2_PII_EDA.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright notice:\n",
    "\n",
    "\n",
    "Data generated for evaluation was created using Fake Name Generator.\n",
    "\n",
    "Fake Name Generator identities by the [Fake Name Generator](https://www.fakenamegenerator.com/) \n",
    "are licensed under a [Creative Commons Attribution-Share Alike 3.0 United States License](http://creativecommons.org/licenses/by-sa/3.0/us/). Fake Name Generator and the Fake Name Generator logo are trademarks of Corban Works, LLC."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2509fbe9adc3579fd0ef23e6a2c6fb50cb745caa174aafdf017283479e60bc43"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
